{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## MOSAIKS feature extraction\n",
        "\n",
        "This tutorial demonstrates the **MOSAIKS** method for extracting _feature vectors_ from satellite imagery patches for use in downstream modeling tasks. It will show:\n",
        "- How to extract 1km$^2$ patches of Sentinel 2 multispectral imagery for a list of latitude, longitude points\n",
        "- How to extract summary features from each of these imagery patches\n",
        "- How to use the summary features in a linear model of the population density at each point\n",
        "\n",
        "### Background\n",
        "\n",
        "Consider the case where you have a dataset of latitude and longitude points assosciated with some dependent variable (for example: population density, weather, housing prices, biodiversity) and, potentially, other independent variables. You would like to model the dependent variable as a function of the independent variables, but instead of including latitude and longitude directly in this model, you would like to include some high dimensional representation of what the Earth looks like at that point (that hopefully explains some of the variance in the dependent variable!). From the computer vision literature, there are various [representation learning techniques](https://en.wikipedia.org/wiki/Feature_learning) that can be used to do this, i.e. extract _features vectors_ from imagery. This notebook gives an implementation of the technique described in [Rolf et al. 2021](https://www.nature.com/articles/s41467-021-24638-z), \"A generalizable and accessible approach to machine learning with global satellite imagery\" called Multi-task Observation using Satellite Imagery & Kitchen Sinks (**MOSAIKS**). For more information about **MOSAIKS** see the [project's webpage](http://www.globalpolicy.science/mosaiks).\n",
        "\n",
        "\n",
        "**Notes**:\n",
        "- This example uses [Sentinel-2 Level-2A data](https://planetarycomputer.microsoft.com/dataset/sentinel-2-l2a). The techniques used here apply equally well to other remote-sensing datasets.\n",
        "- If you're running this on the [Planetary Computer Hub](http://planetarycomputer.microsoft.com/compute), make sure to choose the **GPU - PyTorch** profile when presented with the form to choose your environment."
      ],
      "metadata": {},
      "id": "338d2487"
    },
    {
      "cell_type": "code",
      "source": [
        "# installs dask-geopandas\n",
        "#!pip install -q git+https://github.com/geopandas/dask-geopandas"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1681781736812
        }
      },
      "id": "e33320a4"
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "import time\n",
        "import os\n",
        "import gc\n",
        "import calendar\n",
        "from IPython.display import FileLink\n",
        "\n",
        "RASTERIO_BEST_PRACTICES = dict(  # See https://github.com/pangeo-data/cog-best-practices\n",
        "    CURL_CA_BUNDLE=\"/etc/ssl/certs/ca-certificates.crt\",\n",
        "    GDAL_DISABLE_READDIR_ON_OPEN=\"EMPTY_DIR\",\n",
        "    AWS_NO_SIGN_REQUEST=\"YES\",\n",
        "    GDAL_MAX_RAW_BLOCK_CACHE_SIZE=\"200000000\",\n",
        "    GDAL_SWATH_SIZE=\"200000000\",\n",
        "    VSI_CURL_CACHE_SIZE=\"200000000\",\n",
        ")\n",
        "os.environ.update(RASTERIO_BEST_PRACTICES)\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# contextily package to retrieve tile maps\n",
        "import contextily as ctx\n",
        "import rasterio\n",
        "import rasterio.warp\n",
        "import rasterio.mask\n",
        "import shapely.geometry\n",
        "import geopandas\n",
        "import dask_geopandas\n",
        "import dask.dataframe as dd\n",
        "from dask.distributed import Client, LocalCluster\n",
        "import dask_gateway\n",
        "\n",
        "warnings.filterwarnings(action=\"ignore\", category=UserWarning, module=\"torch\")\n",
        "\n",
        "import pystac_client\n",
        "import planetary_computer as pc\n",
        "\n",
        "# Disabling the benchmarking feature with torch.backends.cudnn.benchmark = False \n",
        "# causes cuDNN to deterministically select an algorithm, possibly at the cost of reduced performance.\n",
        "# https://pytorch.org/docs/stable/notes/randomness.html\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "np.random.seed(43)\n",
        "torch.manual_seed(43)\n",
        "\n",
        "import random\n",
        "random.seed(43)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n"
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'contextily'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset, DataLoader\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# contextily package to retrieve tile maps\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcontextily\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mctx\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrasterio\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrasterio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwarp\u001b[39;00m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'contextily'"
          ]
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1681844051192
        }
      },
      "id": "8e98f0ec"
    },
    {
      "cell_type": "code",
      "source": [
        "# number to features to be generated from each satellite tile fed into the MOSAIKS process\n",
        "num_features = 1000\n",
        "\n",
        "# specifies which of the many satellites to use\n",
        "satellite = \"sentinel-2-l2a\"\n",
        "\n",
        "# the code for Zambia in MPC STAC syntax\n",
        "country_code = 'ZMB'\n",
        "\n",
        "# this decisdes if you generate points to featurize within this notebook or you pull them from another notebook\n",
        "# use_file = True\n",
        "use_file = False"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1681781739435
        }
      },
      "id": "a7c8cf08"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create grid and sample points to featurize"
      ],
      "metadata": {},
      "id": "928608cd"
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "if use_file:\n",
        "    gdf = pd.read_feather('data/keep/ZMB_crop_weights_20k-points.feather')\n",
        "    gdf = (\n",
        "        geopandas\n",
        "        .GeoDataFrame(\n",
        "            gdf, \n",
        "            geometry = geopandas.points_from_xy(x = gdf.lon, y = gdf.lat), \n",
        "            crs='EPSG:4326')\n",
        "    )\n",
        "else:\n",
        "    \n",
        "    ### get country shape in a vector form from a Zambian border geojson file\n",
        "    url = 'https://raw.githubusercontent.com/wmgeolab/geoBoundaries/7d63961ccefe39c0a68e28d5929aa9c866572180/releaseData/gbOpen/ZMB/ADM0/geoBoundaries-ZMB-ADM0_simplified.geojson'\n",
        "    zambia = geopandas.read_file(url)\n",
        "        ### Read in the shapefile for the sea polyggon\n",
        "    gdf_sea = geopandas.read_file('sea_spring/featurize_me.shp', crs = 'EPSG:4326')\n",
        "    \n",
        "    \n",
        "    \n",
        "    ### Create grid of points that will be laid over Zambia\n",
        "    \n",
        "    cell_size = .01  # 0.01 is roughly a 1 km\n",
        "    \n",
        "    xmin, ymin, xmax, ymax = gdf_sea.total_bounds\n",
        "    \n",
        "    xs = list(np.arange(xmin, xmax + cell_size, cell_size))\n",
        "    ys = list(np.arange(ymin, ymax + cell_size, cell_size))\n",
        "    \n",
        "    def make_cell(x, y, cell_size):\n",
        "        ring = [\n",
        "            (x, y),\n",
        "            (x + cell_size, y),\n",
        "            (x + cell_size, y + cell_size),\n",
        "            (x, y + cell_size)\n",
        "        ]\n",
        "        cell = shapely.geometry.Polygon(ring).centroid\n",
        "        return cell"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "CPU times: user 166 ms, sys: 3.64 ms, total: 169 ms\nWall time: 346 ms\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "tags": []
      },
      "id": "aef5d183"
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a local Dask cluster\n",
        "cluster = LocalCluster()\n",
        "client = Client(cluster)\n",
        "\n",
        "# Use adapt() to dynamically scale the number of workers based on workload\n",
        "client.cluster.adapt(minimum=1, maximum=4)\n",
        "\n",
        "# Print the Dask dashboard link\n",
        "print(client.dashboard_link)\n",
        "\n",
        "# MPC\n",
        "#cluster = dask_gateway.GatewayCluster()\n",
        "#client = cluster.get_client()\n",
        "#cluster.adapt(minimum=2, maximum=50)\n",
        "#print(cluster.dashboard_link)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "http://127.0.0.1:8787/status\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1681781740639
        }
      },
      "id": "0cd4eaed-9bc6-4d93-bfdf-9f45919c7fd8"
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# initiates an empty vector\n",
        "center_points = []\n",
        "    \n",
        "for x in xs:\n",
        "    for y in ys:\n",
        "        cell = make_cell(x, y, cell_size)\n",
        "        center_points.append(cell)\n",
        "        \n",
        "### Put grid into a GeDataFrame for cropping to country shape\n",
        "gdf = geopandas.GeoDataFrame({'geometry': center_points}, crs = 'EPSG:4326')\n",
        "gdf['lon'], gdf['lat'] = gdf.geometry.x, gdf.geometry.y\n",
        "gdf = gdf.sample(frac = 0.1, random_state=43, ignore_index=False)\n",
        "\n",
        "# convert GeoDataFrame to Dask GeoDataFrame\n",
        "dask_gdf = dask_geopandas.from_geopandas(gdf, npartitions=47)\n",
        "\n",
        "# use Dask to apply the within() method in parallel\n",
        "dask_gdf_within = dask_gdf.map_partitions(\n",
        "    lambda partition: partition[partition.geometry.within(zambia.unary_union)],\n",
        "    meta=gdf.head(0)\n",
        ")\n",
        "\n",
        "# convert Dask GeoDataFrame back to GeoDataFrame\n",
        "gdf = dask_gdf_within.compute()\n",
        "\n",
        "points = gdf[[\"lon\", \"lat\"]].to_numpy()\n",
        "pt_len = gdf.shape[0]\n",
        "gdf.shape"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2023-04-18 01:35:44,916 - distributed.scheduler - WARNING - Received heartbeat from unregistered worker 'tcp://127.0.0.1:46455'.\n2023-04-18 01:35:44,930 - distributed.worker - ERROR - Scheduler was unaware of this worker 'tcp://127.0.0.1:46455'. Shutting down.\n2023-04-18 01:35:44,952 - distributed.scheduler - WARNING - Received heartbeat from unregistered worker 'tcp://127.0.0.1:45295'.\n2023-04-18 01:35:44,984 - distributed.worker - ERROR - Scheduler was unaware of this worker 'tcp://127.0.0.1:45295'. Shutting down.\nTask exception was never retrieved\nfuture: <Task finished name='Task-769' coro=<Worker.close() done, defined at /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/distributed/utils.py:750> exception=CommClosedError('in <TCP (closed) ConnectionPool.close_gracefully local=tcp://127.0.0.1:42120 remote=tcp://127.0.0.1:37193>: Stream is closed')>\nTraceback (most recent call last):\n  File \"/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/distributed/comm/tcp.py\", line 225, in read\n    frames_nbytes = await stream.read_bytes(fmt_size)\ntornado.iostream.StreamClosedError: Stream is closed\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/distributed/utils.py\", line 752, in wrapper\n    return await func(*args, **kwargs)\n  File \"/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/distributed/worker.py\", line 1563, in close\n    await r.close_gracefully(reason=reason)\n  File \"/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/distributed/core.py\", line 1268, in send_recv_from_rpc\n    return await send_recv(comm=comm, op=key, **kwargs)\n  File \"/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/distributed/core.py\", line 1027, in send_recv\n    response = await comm.read(deserializers=deserializers)\n  File \"/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/distributed/comm/tcp.py\", line 241, in read\n    convert_stream_closed_error(self, e)\n  File \"/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/distributed/comm/tcp.py\", line 144, in convert_stream_closed_error\n    raise CommClosedError(f\"in {obj}: {exc}\") from exc\ndistributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.close_gracefully local=tcp://127.0.0.1:42120 remote=tcp://127.0.0.1:37193>: Stream is closed\nTask exception was never retrieved\nfuture: <Task finished name='Task-771' coro=<Worker.close() done, defined at /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/distributed/utils.py:750> exception=CommClosedError('in <TCP (closed) ConnectionPool.close_gracefully local=tcp://127.0.0.1:35820 remote=tcp://127.0.0.1:41371>: Stream is closed')>\nTraceback (most recent call last):\n  File \"/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/distributed/comm/tcp.py\", line 225, in read\n    frames_nbytes = await stream.read_bytes(fmt_size)\ntornado.iostream.StreamClosedError: Stream is closed\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/distributed/utils.py\", line 752, in wrapper\n    return await func(*args, **kwargs)\n  File \"/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/distributed/worker.py\", line 1563, in close\n    await r.close_gracefully(reason=reason)\n  File \"/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/distributed/core.py\", line 1268, in send_recv_from_rpc\n    return await send_recv(comm=comm, op=key, **kwargs)\n  File \"/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/distributed/core.py\", line 1027, in send_recv\n    response = await comm.read(deserializers=deserializers)\n  File \"/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/distributed/comm/tcp.py\", line 241, in read\n    convert_stream_closed_error(self, e)\n  File \"/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/distributed/comm/tcp.py\", line 144, in convert_stream_closed_error\n    raise CommClosedError(f\"in {obj}: {exc}\") from exc\ndistributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.close_gracefully local=tcp://127.0.0.1:35820 remote=tcp://127.0.0.1:41371>: Stream is closed\n2023-04-18 01:35:48,346 - distributed.nanny - WARNING - Worker process still alive after 3.1999989318847657 seconds, killing\n2023-04-18 01:35:48,470 - distributed.nanny - WARNING - Worker process still alive after 3.1999992370605472 seconds, killing\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "CPU times: user 51.8 s, sys: 11.6 s, total: 1min 3s\nWall time: 1min 5s\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "(61521, 3)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {},
      "id": "ca65d16c-a4f9-45bd-99ee-f8efc2dc1a29"
    },
    {
      "cell_type": "code",
      "source": [
        "# Close the client\n",
        "client.close()\n",
        "\n",
        "# Close the cluster\n",
        "cluster.close()\n",
        "\n",
        "#MPC\n",
        "#cluster.close()"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1681781806214
        }
      },
      "id": "ba6fd1a0-f347-4440-9722-7f80f2d15fd9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we define the pytorch model that we will use to extract the features and a helper method. The **MOSAIKS** methodology describes several ways to do this and we use the simplest."
      ],
      "metadata": {
        "tags": []
      },
      "id": "f40e13b0"
    },
    {
      "cell_type": "code",
      "source": [
        "class RCF(nn.Module):\n",
        "    \"\"\"A model for extracting Random Convolution Features (RCF) from input imagery.\"\"\"\n",
        "    def __init__(self, num_features=16, kernel_size=3, num_input_channels=3):\n",
        "        super(RCF, self).__init__()\n",
        "        # We create `num_features / 2` filters so require `num_features` to be divisible by 2\n",
        "        assert num_features % 2 == 0, \"Please enter an even number of features.\"\n",
        "        # Applies a 2D convolution over an input image composed of several input planes.\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            num_input_channels,\n",
        "            num_features // 2,\n",
        "            kernel_size=kernel_size,\n",
        "            stride=1,\n",
        "            padding=0,\n",
        "            dilation=1,\n",
        "            bias=True,\n",
        "        )\n",
        "        # Fills the input Tensor 'conv1.weight' with values drawn from the normal distribution\n",
        "        nn.init.normal_(self.conv1.weight, mean=0.0, std=1.0) \n",
        "        # Fills the input Tensor 'conv1.bias' with the value 'val = -1'.\n",
        "        nn.init.constant_(self.conv1.bias, -1.0)\n",
        "    def forward(self, x):\n",
        "        # The rectified linear activation function or ReLU for short is a piecewise linear function \n",
        "        # that will output the input directly if it is positive, otherwise, it will output zero.\n",
        "        x1a = F.relu(self.conv1(x), inplace=True)\n",
        "        # The below step is where we take the inverse which is appended later\n",
        "        x1b = F.relu(-self.conv1(x), inplace=True)\n",
        "        # Applies a 2D adaptive average pooling over an input signal composed of several input planes.\n",
        "        x1a = F.adaptive_avg_pool2d(x1a, (1, 1)).squeeze()\n",
        "        x1b = F.adaptive_avg_pool2d(x1b, (1, 1)).squeeze()\n",
        "        if len(x1a.shape) == 1:  # case where we passed a single input\n",
        "            return torch.cat((x1a, x1b), dim=0)\n",
        "        elif len(x1a.shape) == 2:  # case where we passed a batch of > 1 inputs\n",
        "            return torch.cat((x1a, x1b), dim=1)"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "tags": [],
        "gather": {
          "logged": 1681781806353
        }
      },
      "id": "e85ddac5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we initialize the model and pytorch components"
      ],
      "metadata": {},
      "id": "4f0600b1"
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\")\n",
        "model = RCF(num_features).eval().to(device)"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1681781813729
        }
      },
      "id": "eece8ad5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extract features from the imagery around each point\n",
        "\n",
        "We need to find a suitable Sentinel 2 scene for each point. As usual, we'll use `pystac-client` to search for items matching some conditions, but we don't just want do make a `.search()` call for each of the 67,968 remaining points. Each HTTP request is relatively slow. Instead, we will *batch* or points and search *in parallel*.\n",
        "\n",
        "We need to be a bit careful with how we batch up our points though. Since a single Sentinel 2 scene will cover many points, we want to make sure that points which are spatially close together end up in the same batch. In short, we need to spatially partition the dataset. This is implemented in `dask-geopandas`.\n",
        "\n",
        "So the overall workflow will be\n",
        "\n",
        "1. Find an appropriate STAC item for each point (in parallel, using the spatially partitioned dataset)\n",
        "2. Feed the points and STAC items to a custom Dataset that can read imagery given a point and the URL of a overlapping S2 scene\n",
        "3. Use a custom Dataloader, which uses our Dataset, to feed our model imagery and save the corresponding features"
      ],
      "metadata": {},
      "id": "4cd81227"
    },
    {
      "cell_type": "code",
      "source": [
        "NPARTITIONS = 250\n",
        "\n",
        "ddf = dask_geopandas.from_geopandas(gdf, npartitions=1)\n",
        "hd = ddf.hilbert_distance().compute()\n",
        "gdf[\"hd\"] = hd\n",
        "gdf = gdf.sort_values(\"hd\")\n",
        "\n",
        "dgdf = dask_geopandas.from_geopandas(gdf, npartitions=NPARTITIONS, sort=False)\n",
        "\n",
        "# deletes these items from memmory to free up space\n",
        "del ddf\n",
        "del hd\n",
        "del gdf\n",
        "\n",
        "gc.collect()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "430"
          },
          "metadata": {}
        }
      ],
      "execution_count": 10,
      "metadata": {
        "tags": [],
        "gather": {
          "logged": 1681781814463
        }
      },
      "id": "d8fdc9d9"
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "year_start = 2017\n",
        "year_end = 2021\n",
        "print(\n",
        "    \"Using:\\n\", \n",
        "    f\"  {satellite} imagery \\n\",\n",
        "    f\"  Looking for monthly images for {pt_len} points \\n\",\n",
        "    f\"  Calulating {num_features} features \\n\",\n",
        "    f\"  between {year_start} and {year_end} \\n\")\n",
        "for yr in range(year_start, year_end+1):\n",
        "    if (yr == 2017) :\n",
        "        month_range = range(2, 13)\n",
        "    else:\n",
        "        month_range = range(1, 13)\n",
        "        \n",
        "    for mn in month_range:\n",
        "        features = pd.DataFrame()\n",
        "        ft = []\n",
        "        if mn < 10:\n",
        "            month = \"0\"+str(mn)\n",
        "        else:\n",
        "            month = mn\n",
        "        def query(points):\n",
        "            \"\"\"\n",
        "            Find a STAC item for points in the `points` DataFrame\n",
        "            \n",
        "            Parameters\n",
        "            ----------\n",
        "            points : geopandas.GeoDataFrame\n",
        "                A GeoDataFrame\n",
        "                \n",
        "            Returns\n",
        "            -------\n",
        "            geopandas.GeoDataFrame\n",
        "                A new geopandas.GeoDataFrame with a `stac_item` column containing the STAC\n",
        "                item that covers each point.\n",
        "            \"\"\"\n",
        "            intersects = shapely.geometry.mapping(points.unary_union.convex_hull)\n",
        "            \n",
        "            catalog = pystac_client.Client.open(\n",
        "                \"https://planetarycomputer.microsoft.com/api/stac/v1\"\n",
        "            )\n",
        "            # Define search date range for query\n",
        "            ending_day = calendar.monthrange(yr, int(mn))[1]\n",
        "            search_start = f\"{yr}-{month}-01\" \n",
        "            search_end = f\"{yr}-{month}-{ending_day}\" \n",
        "            \n",
        "            # The time frame in which we search for non-cloudy imagery\n",
        "            search = catalog.search(\n",
        "                collections=[satellite],\n",
        "                intersects=intersects,\n",
        "                datetime=[search_start, search_end],\n",
        "                query={\"eo:cloud_cover\": {\"lt\": 10}},\n",
        "                limit=500,\n",
        "            )\n",
        "            ic = search.get_all_items_as_dict()\n",
        "            features = ic[\"features\"]\n",
        "            features_d = {item[\"id\"]: item for item in features}\n",
        "            data = {\n",
        "                \"eo:cloud_cover\": [],\n",
        "                \"geometry\": [],\n",
        "            }\n",
        "            index = []\n",
        "            for item in features:\n",
        "                data[\"eo:cloud_cover\"].append(item[\"properties\"][\"eo:cloud_cover\"])\n",
        "                data[\"geometry\"].append(shapely.geometry.shape(item[\"geometry\"]))\n",
        "                index.append(item[\"id\"])\n",
        "            items = geopandas.GeoDataFrame(data, index=index, geometry=\"geometry\").sort_values(\n",
        "                \"eo:cloud_cover\"\n",
        "            )\n",
        "            point_list = points.geometry.tolist()\n",
        "            point_items = []\n",
        "            for point in point_list:\n",
        "                covered_by = items[items.covers(point)]\n",
        "                if len(covered_by):\n",
        "                    point_items.append(features_d[covered_by.index[0]])\n",
        "                else:\n",
        "                    # There weren't any scenes matching our conditions for this point (too cloudy)\n",
        "                    point_items.append(None)\n",
        "            return points.assign(stac_item=point_items)\n",
        "        \n",
        "        tic = time.time()\n",
        "        print(\"Matching images to points for: \", mn, \"-\", yr, sep = \"\")\n",
        "        \n",
        "        with Client(n_workers=8) as client:\n",
        "            meta = dgdf._meta.assign(stac_item=[])\n",
        "            df2 = dgdf.map_partitions(query, meta=meta).compute()\n",
        "        df3 = df2.dropna(subset=[\"stac_item\"])\n",
        "        matching_urls = [\n",
        "            pc.sign(item[\"assets\"][\"visual\"][\"href\"]) for item in df3.stac_item.tolist()\n",
        "        ]\n",
        "        points = df3[[\"lon\", \"lat\"]].to_numpy()\n",
        "        \n",
        "        print(\"Found acceptable images for \", \n",
        "              points.shape[0], \n",
        "              \" points in \", \n",
        "              f\"{time.time()-tic:0.2f} seconds\", \n",
        "              sep = \"\")\n",
        "        \n",
        "        class CustomDataset(Dataset):\n",
        "            def __init__(self, points, fns, buffer=0.005):\n",
        "                self.points = points\n",
        "                self.fns = fns\n",
        "                self.buffer = buffer\n",
        "            def __len__(self):\n",
        "                return self.points.shape[0]\n",
        "            def __getitem__(self, idx):\n",
        "                lon, lat = self.points[idx]\n",
        "                fn = self.fns[idx]\n",
        "                if fn is None:\n",
        "                    return None\n",
        "                else:\n",
        "                    point_geom = shapely.geometry.mapping(shapely.geometry.Point(lon, lat))\n",
        "                    with rasterio.Env():\n",
        "                        with rasterio.open(fn, \"r\") as f:\n",
        "                            point_shape = shapely.geometry.shape(point_geom)\n",
        "                            mask_shape = point_shape.buffer(self.buffer).envelope\n",
        "                            mask_geom = shapely.geometry.mapping(mask_shape)\n",
        "                            mask_geom = rasterio.warp.transform_geom(\n",
        "                                \"epsg:4326\", f.crs.to_string(), mask_geom\n",
        "                            )\n",
        "                            try:\n",
        "                                out_image, out_transform = rasterio.mask.mask(\n",
        "                                    f, [mask_geom], crop=True\n",
        "                                )\n",
        "                            except ValueError as e:\n",
        "                                if \"Input shapes do not overlap raster.\" in str(e):\n",
        "                                    return None\n",
        "                    out_image = out_image / 255.0\n",
        "                    out_image = torch.from_numpy(out_image).float()\n",
        "                    return out_image\n",
        "        dataset = CustomDataset(points, matching_urls)\n",
        "        dataloader = DataLoader(\n",
        "            dataset,\n",
        "            batch_size=16,\n",
        "            shuffle=False,\n",
        "            num_workers=os.cpu_count()*2,\n",
        "            collate_fn=lambda x: x,\n",
        "            pin_memory=False,\n",
        "        )\n",
        "        x_all = np.zeros((points.shape[0], num_features), dtype=float)\n",
        "        tic = time.time()\n",
        "        i = 0\n",
        "        print(\"Featurizing: \", month, \"-\", yr, sep = \"\")\n",
        "        for images in dataloader:\n",
        "            for image in images:\n",
        "                if i % 1000 == 0:\n",
        "                    print(\n",
        "                        f\"{i}/{points.shape[0]} -- {i / points.shape[0] * 100:0.2f}%\"\n",
        "                        + f\" -- {time.time()-tic:0.2f} seconds\"\n",
        "                    )\n",
        "                    tic = time.time()\n",
        "                if image is not None:\n",
        "                    # A full image should be ~101x101 pixels (i.e. ~1km^2 at a 10m/px spatial\n",
        "                    # resolution), however we can receive smaller images if an input point\n",
        "                    # happens to be at the edge of a S2 scene (a literal edge case). To deal\n",
        "                    # with these (edge) cases we crudely drop all images where the spatial\n",
        "                    # dimensions aren't both greater than 20 pixels.\n",
        "                    if image.shape[1] >= 20 and image.shape[2] >= 20:\n",
        "                        image = image.to(device)\n",
        "                        with torch.no_grad():\n",
        "                            feats = model(image.unsqueeze(0)).cpu().numpy()\n",
        "                        x_all[i] = feats\n",
        "                    else:\n",
        "                        # this happens if the point is close to the edge of a scene\n",
        "                        # (one or both of the spatial dimensions of the image are very small)\n",
        "                        pass\n",
        "                else:\n",
        "                    pass  # this happens if we do not find a S2 scene for some point\n",
        "                i += 1\n",
        "        features_monthly = pd.DataFrame(x_all)\n",
        "        features_monthly[[\"lon\", \"lat\"]] = points.tolist()\n",
        "        features_monthly['year'] = yr\n",
        "        features_monthly['month'] = mn\n",
        "        \n",
        "        ft.append(features_monthly)\n",
        "        \n",
        "        features = pd.concat(ft).reset_index(drop = True)\n",
        "    \n",
        "        features.columns = features.columns.astype(str)\n",
        "        \n",
        "        # Save the features to a feather file\n",
        "        file_name = (f'data/{satellite}_bands-3-4-5_{country_code}_{pt_len/1000:.0f}'+\n",
        "                 f'k-points_{num_features}-features_{yr}_{mn}.feather')\n",
        "    \n",
        "        print(\"Saving file as:\", file_name)\n",
        "        features.to_feather(file_name)\n",
        "    \n",
        "        # display(FileLink(file_name))\n",
        "    \n",
        "        print(\"Save finished!\")\n",
        "        \n",
        "        # Free memory before loop iterates\n",
        "        print(\"Freeing RAM\")\n",
        "        del meta\n",
        "        del query\n",
        "        del df2\n",
        "        del df3\n",
        "        del points\n",
        "        del dataset\n",
        "        del dataloader\n",
        "        del x_all\n",
        "        del features_monthly\n",
        "        del CustomDataset\n",
        "        del matching_urls\n",
        "        del ft\n",
        "        del features\n",
        "        gc.collect()\n",
        "        print('')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Using:\n   sentinel-2-l2a imagery \n   Looking for monthly images for 61521 points \n   Calulating 1000 features \n   between 2017 and 2021 \n\nMatching images to points for: 1-2017\nFound acceptable images for 2606 points in 24.05 seconds\nFeaturizing: 01-2017\n0/2606 -- 0.00% -- 1.55 seconds\n1000/2606 -- 38.37% -- 3.24 seconds\n2000/2606 -- 76.75% -- 4.18 seconds\nSaving file as: data/sentinel-2-l2a_bands-3-4-5_ZMB_62k-points_1000-features_2017_1.feather\nSave finished!\nFreeing RAM\n\nMatching images to points for: 2-2017\nFound acceptable images for 3093 points in 23.63 seconds\nFeaturizing: 02-2017\n0/3093 -- 0.00% -- 1.46 seconds\n1000/3093 -- 32.33% -- 3.77 seconds\n2000/3093 -- 64.66% -- 3.22 seconds\n3000/3093 -- 96.99% -- 3.73 seconds\nSaving file as: data/sentinel-2-l2a_bands-3-4-5_ZMB_62k-points_1000-features_2017_2.feather\nSave finished!\nFreeing RAM\n\nMatching images to points for: 3-2017\nFound acceptable images for 12555 points in 23.84 seconds\nFeaturizing: 03-2017\n0/12555 -- 0.00% -- 1.58 seconds\n1000/12555 -- 7.96% -- 4.02 seconds\n2000/12555 -- 15.93% -- 3.51 seconds\n3000/12555 -- 23.89% -- 3.84 seconds\n4000/12555 -- 31.86% -- 3.24 seconds\n5000/12555 -- 39.82% -- 3.53 seconds\n6000/12555 -- 47.79% -- 3.82 seconds\n7000/12555 -- 55.75% -- 3.36 seconds\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2023-04-18 03:01:20,586 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\nTraceback (most recent call last):\n  File \"/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/distributed/comm/tcp.py\", line 225, in read\n    frames_nbytes = await stream.read_bytes(fmt_size)\ntornado.iostream.StreamClosedError: Stream is closed\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/distributed/worker.py\", line 1234, in heartbeat\n    response = await retry_operation(\n  File \"/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/distributed/utils_comm.py\", line 434, in retry_operation\n    return await retry(\n  File \"/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/distributed/utils_comm.py\", line 413, in retry\n    return await coro()\n  File \"/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/distributed/core.py\", line 1268, in send_recv_from_rpc\n    return await send_recv(comm=comm, op=key, **kwargs)\n  File \"/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/distributed/core.py\", line 1027, in send_recv\n    response = await comm.read(deserializers=deserializers)\n  File \"/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/distributed/comm/tcp.py\", line 241, in read\n    convert_stream_closed_error(self, e)\n  File \"/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/distributed/comm/tcp.py\", line 144, in convert_stream_closed_error\n    raise CommClosedError(f\"in {obj}: {exc}\") from exc\ndistributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:47646 remote=tcp://127.0.0.1:41935>: Stream is closed\n2023-04-18 03:01:57,674 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\nTraceback (most recent call last):\n  File \"/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/distributed/comm/tcp.py\", line 225, in read\n    frames_nbytes = await stream.read_bytes(fmt_size)\ntornado.iostream.StreamClosedError: Stream is closed\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/distributed/worker.py\", line 1234, in heartbeat\n    response = await retry_operation(\n  File \"/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/distributed/utils_comm.py\", line 434, in retry_operation\n    return await retry(\n  File \"/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/distributed/utils_comm.py\", line 413, in retry\n    return await coro()\n  File \"/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/distributed/core.py\", line 1268, in send_recv_from_rpc\n    return await send_recv(comm=comm, op=key, **kwargs)\n  File \"/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/distributed/core.py\", line 1027, in send_recv\n    response = await comm.read(deserializers=deserializers)\n  File \"/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/distributed/comm/tcp.py\", line 241, in read\n    convert_stream_closed_error(self, e)\n  File \"/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/distributed/comm/tcp.py\", line 144, in convert_stream_closed_error\n    raise CommClosedError(f\"in {obj}: {exc}\") from exc\ndistributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:56014 remote=tcp://127.0.0.1:38155>: Stream is closed\n"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "File \u001b[0;32m<timed exec>:144\u001b[0m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/torch/utils/data/dataloader.py:652\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    650\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    651\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 652\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    655\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    656\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1330\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1327\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1329\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1330\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1332\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1333\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1296\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1292\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1293\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1294\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1295\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1296\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1297\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1298\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1134\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1122\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1123\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1134\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1135\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1136\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1137\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1139\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/multiprocessing/queues.py:107\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[1;32m    106\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    108\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/multiprocessing/connection.py:424\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 424\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    928\u001b[0m     deadline \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[1;32m    933\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [key\u001b[38;5;241m.\u001b[39mfileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/selectors.py:415\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "execution_count": 15,
      "metadata": {
        "tags": [],
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "id": "9028e818"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml-pt-tf",
      "language": "python",
      "display_name": "Python 3.8 - Pytorch and Tensorflow"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python38-azureml-pt-tf"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}